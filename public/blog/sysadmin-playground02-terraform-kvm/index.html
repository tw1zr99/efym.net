<!DOCTYPE html>
<html lang="en">
<head>
	<title>sysadmin playground part 02 | terraform and kvm üñ• | efym.net</title>
	<link rel="canonical" href="http://efym.net/">
	<link rel='alternate' type='application/rss+xml' title="efym.net RSS" href='/index.xml'>
	<link rel='stylesheet' type='text/css' href='/style.css'>
	<link rel="icon" href="/favicon.ico">
	<meta name="description" content="Using Terraform with the KVM provider and cloud-init to spin up virtual machines while keeping the infrastructure&rsquo;s configuration as code.">
	<meta name="keywords" content="sysadmin, linux">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="robots" content="index, follow">
	<meta charset="utf-8">
</head>
<body>
<div class="topbar">
<nav class="menu">
<div class="nav-left">
 <ul>
	<li><a href="/"><img class="logo" src="/svg/efym/net.svg" alt="logo"></a></li>
  </ul>
</div>
<div class="nav-right">
 <ul>
	<li><a href="/contact">üì† contact</a></li>
	<li><a href="/support">üí∏ support</a></li>
	<li><a href="https://dash.efym.net">üñ•Ô∏è services</a></li>
	<li><a href="/blog">üìù blog</a></li>
	<li><a href="/about">üë§ about</a></li>
  </ul>
</div>
</nav>
</div>
<main>
<header><h1>Sysadmin Playground Part 02 | Terraform and KVM üñ•</h1></header>
<article>
<p class="date">July 13, 2021</p>
<p>Using Terraform with the KVM provider and cloud-init to spin up virtual machines while keeping the infrastructure&rsquo;s configuration as code.</p>
<hr>
<strong>This post is part of a series, follow the links to the other parts:</strong>
<br>


<a href="/blog/sysadmin-playground01-intro/">Sysadmin Playground Part 01 | Intro</a><br>

<a href="/blog/sysadmin-playground02-terraform-kvm/">Sysadmin Playground Part 02 | Terraform and KVM üñ•</a><br>

<a href="/blog/sysadmin-playground03-ansible-docker/">Sysadmin Playground Part 03 | Ansible and Docker üì¶</a><br>

<a href="/blog/sysadmin-playground04-openldap/">Sysadmin Playground Part 04 | OpenLDAP üë•</a><br>

<a href="/blog/sysadmin-playground05-passwords-ansible-vault/">Sysadmin Playground Part 05 | Passwords and Ansible Vault üîí</a><br>

<a href="/blog/sysadmin-playground06-centralized-logs/">Sysadmin Playground Part 06 | Centralized Logs üìÑ</a><br>

<a href="/blog/sysadmin-playground07-email/">Sysadmin Playground Part 07 | E-mail ‚úâÔ∏è</a><br>

<a href="/blog/sysadmin-playground08-nfs/">Sysadmin Playground Part 08 | NFS üíΩ</a><br>


<hr>
<h2 id="visualizing-the-topology">Visualizing the topology</h2>
<p>By the end of this post our infrastructure should look like this diagram, we&rsquo;ll only be working with 3 VMs for now and we will set up the rest in a later post; at the very least it should be identical from the hypervisor and downstream.</p>
<p><img src="/blog/sysadmin-playground/1.png" alt=""></p>
<h2 id="setup-terraform-to-work-with-the-libvirt-provider">Setup Terraform to work with the libvirt provider</h2>
<p>Install <a href="https://www.terraform.io">Terraform</a> into the box serving as the KVM hypervisor; mine is my homeserver running Debian.</p>
<p>Make a directory which will hold all the files we&rsquo;re going to work with.</p>
<p>In order to use the <a href="https://github.com/dmacvicar/terraform-provider-libvirt">libvirt provider</a> we need to define it within <strong>Terraform</strong>&rsquo;s environment. For this we make a dedicated file called <strong>providers.tf</strong> which looks like this:</p>
<p><strong><code>$ cat providers.tf</code></strong></p>
<pre tabindex="0"><code>terraform {
  required_providers {
    libvirt = {
      source = &#34;dmacvicar/libvirt&#34;
    }
  }
}

provider &#34;libvirt&#34; {
uri = &#34;qemu:///system&#34;
}
</code></pre><p>Now we type:</p>
<p><code>$ terraform init</code></p>
<p>This will download the provider and our <strong>Terraform</strong> environment will be initialized.</p>
<p>There&rsquo;s a bug with <strong>AppArmor</strong> templates and <strong>KVM/Qemu</strong> regarding ownership of the hypervisor volumes, we can get around it by appending a line to <code>/etc/libvirt/qemu.conf</code>.</p>
<p><code>$ echo 'security_driver = &quot;none&quot;' &gt;&gt; /etc/libvirt/qemu.conf</code></p>
<h2 id="terraform-configuration-file-for-first-box">Terraform configuration file for first box</h2>
<p>Let&rsquo;s grab a cloud-ready image, I&rsquo;m using <a href="https://cloud.debian.org/images/cloud/bullseye/daily/latest/debian-11-genericcloud-amd64-daily.qcow2">Debian 11 (Bullseye)</a>. This is a qcow2 cloud image which boots straight into Debian without needing any installation. In order to set the root password, <strong>ssh</strong> authentication keys and hostname we will use <strong>cloud-init</strong> which is nicely supported by our <strong>Terraform</strong> libvirt provider. But first let&rsquo;s create the <strong>Terraform</strong> file for our first box.</p>
<p>I name the files after the boxes hostnames I plan to use, this first one we&rsquo;ll name <strong>doris</strong>. So we create <code>doris.tf</code> looking like this:</p>
<p><strong><code>$ cat doris.tf</code></strong></p>
<pre tabindex="0"><code>resource &#34;libvirt_volume&#34; &#34;doris&#34; {
  name = &#34;doris&#34;
  pool = &#34;default&#34;
  source = &#34;https://cloud.debian.org/images/cloud/bullseye/daily/latest/debian-11-generic-amd64-daily.qcow2&#34;
  format = &#34;qcow2&#34;
}

resource &#34;libvirt_cloudinit_disk&#34; &#34;commoninit-doris&#34; {
          name = &#34;commoninit-doris.iso&#34;
          pool = &#34;default&#34;
          user_data = &#34;${data.template_file.user_data-doris.rendered}&#34;
        }

data &#34;template_file&#34; &#34;user_data-doris&#34; {
  template = &#34;${file(&#34;${path.module}/cloud_inits/cloud_init-doris.cfg&#34;)}&#34;
}

resource &#34;libvirt_domain&#34; &#34;doris&#34; {
  name = &#34;doris&#34;
  memory = &#34;512&#34;
  vcpu = 1

  cloudinit = &#34;${libvirt_cloudinit_disk.commoninit-doris.id}&#34;

  network_interface {
    network_name = &#34;default&#34;
        mac = &#34;52:54:00:8f:52:f2&#34;
  }

  disk {
       volume_id = &#34;${libvirt_volume.doris.id}&#34;
  }

  console {
    type        = &#34;pty&#34;
    target_port = &#34;0&#34;
    target_type = &#34;serial&#34;
  }

  console {
        type = &#34;pty&#34;
        target_type = &#34;virtio&#34;
        target_port = &#34;1&#34;
  }

  graphics {
    type = &#34;vnc&#34;
    listen_type = &#34;address&#34;
    autoport = &#34;true&#34;
  }
}
</code></pre><p>Feel free to adjust the virtual CPU cores and amount of RAM for the box.</p>
<h2 id="cloud-init">Cloud-init</h2>
<p>As mentioned above we need to set up <strong>cloud-init</strong> to configure password and <strong>ssh</strong>-based authentication on the boxes. Each box will have its own <strong>cloud-init</strong> file.</p>
<p>We&rsquo;ll make a directory to hold these files:</p>
<p><code>$ mkdir cloud_inits</code></p>
<p>Inside this directory we&rsquo;ll create <code>cloud_init-doris.cfg</code> (the name is important since this is the name we&rsquo;re referencing in <code>doris.tf</code>, you may change it to whatever scheme you want but you&rsquo;ll also need to change the referencing in the <strong>Terraform</strong> file) the file should look like the following:</p>
<p><strong><code>$ cat cloud_inits/cloud_init-doris.cfg</code></strong></p>
<pre tabindex="0"><code>#cloud-config
# vim: syntax=yaml
users:
  - name: root
    ssh_authorized_keys:
       - ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIOY/U6D5FZ54e+PQqZ2j6DtBsqqm3LTa19e99KoiPduZ

ssh_pwauth: True
chpasswd:
  list: |
     root:nyaa
  expire: False
disable_root: false

growpart:
  mode: auto
  devices: [&#39;/&#39;]

runcmd:
 - sed  -i &#39;/PermitRootLogin/s/.*/PermitRootLogin without-password/&#39; /etc/ssh/sshd_config
 - systemctl restart sshd
 - hostnamectl set-hostname doris.pygrn.lab
</code></pre><p>Change the entry under <strong>ssh_authorized_keys</strong> to reflect your ssh public key, change the entry under <strong>chpasswd</strong> to whatever password you want root to have, I&rsquo;m simply using &lsquo;<strong>nyaa</strong>&rsquo; because this network is an internal playground and won&rsquo;t be accessible from outside my LAN; but one should NEVER use such a simplistic password for a root user (or any other user for that matter) in a production environment.</p>
<p>The entries under <strong>runcmd</strong> do the following:</p>
<ul>
<li>The first entry modifies <code>/etc/ssh/sshd_config</code> to allow root login through <strong>ssh</strong>.</li>
<li>The second one restart the <strong>ssh</strong> daemon to apply the changes.</li>
<li>The third one sets the box&rsquo;s hostname. The hostname is a FQDN, this is especially important because we&rsquo;ll be setting up DNS zones in shortly as well as static IP addresses at the hypervisor level among other things later.</li>
</ul>
<p>Copy the boxes file configuration and modify its file name and name of VM to create a different VM Terraform file.</p>
<p><code>$ cp doris.tf cutxn.tf</code></p>
<p><code>$ sed -i 's/doris/cutxn/g' cutxn.tf</code></p>
<p>And again for a third VM:</p>
<p><code>$ cp doris.tf cutxo.tf</code></p>
<p><code>$ sed -i 's/doris/cutxo/g' cutxo.tf</code></p>
<p>We will also change the MAC addresses of the second and third boxes to something different so they don&rsquo;t interfere with each other on the network:</p>
<p><code>$ sed -i 's/mac = &quot;52:54:00:8f:52:f2&quot;/mac = &quot;52:54:00:8f:53:f3&quot;/g' cutxn.tf</code></p>
<p><code>$ sed -i 's/mac = &quot;52:54:00:8f:52:f2&quot;/mac = &quot;52:54:00:8f:54:f4&quot;/g' cutxo.tf</code></p>
<p>Now we do the same for the cloud-init files:</p>
<p><code>$ cp cloud_inits/cloud_init-doris.cfg cloud_inits/cloud_init-cutxn.cfg</code></p>
<p><code>$ sed -i 's/doris/cutxn/g' cloud_inits/cloud_init-cutxn.cfg</code></p>
<p>Third file:</p>
<p><code>$ cp cloud_inits/cloud_init-doris.cfg cloud_inits/cloud_init-cutxo.cfg</code></p>
<p><code>$ sed -i 's/doris/cutxo/g' cloud_inits/cloud_init-cutxo.cfg</code></p>
<h2 id="kvm-hypervisor-dns-configuration">KVM hypervisor DNS configuration</h2>
<p>In order to set up a local DNS zone and static IPs for our virtual machines we will edit the default KVM network:</p>
<p><code>$ virsh net-edit --network default</code></p>
<p>We&rsquo;ll add the following lines to the configuration file:</p>
<!-- raw HTML omitted -->
<p>Here&rsquo;s my complete configuration after applying the changes as an example:</p>
<pre tabindex="0"><code>&lt;network&gt;
  &lt;name&gt;default&lt;/name&gt;
  &lt;uuid&gt;xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx&lt;/uuid&gt;
  &lt;forward mode=&#39;nat&#39;/&gt;
  &lt;bridge name=&#39;virbr0&#39; stp=&#39;on&#39; delay=&#39;0&#39;/&gt;
  &lt;mac address=&#39;52:54:00:b4:81:a8&#39;/&gt;
  &lt;domain name=&#39;pygrn.lab&#39; localOnly=&#39;yes&#39;/&gt;
  &lt;ip address=&#39;192.168.122.1&#39; netmask=&#39;255.255.255.0&#39;&gt;
    &lt;dhcp&gt;
      &lt;range start=&#39;192.168.122.2&#39; end=&#39;192.168.122.254&#39;/&gt;
      &lt;host mac=&#39;52:54:00:8f:52:f2&#39; name=&#39;doris.pygrn.lab&#39; ip=&#39;192.168.122.2&#39;/&gt;
      &lt;host mac=&#39;52:54:00:8f:53:f3&#39; name=&#39;cutxn.pygrn.lab&#39; ip=&#39;192.168.122.3&#39;/&gt;
      &lt;host mac=&#39;52:54:00:8f:54:f4&#39; name=&#39;cutxo.pygrn.lab&#39; ip=&#39;192.168.122.4&#39;/&gt;
    &lt;/dhcp&gt;
  &lt;/ip&gt;
&lt;/network&gt;
</code></pre><p>Restart the KVM default network:</p>
<p><code>$ virsh net-destroy --network default</code></p>
<p><code>$ virsh net-start --network default</code></p>
<h2 id="terraform-deployment">Terraform deployment</h2>
<p>Let&rsquo;s check our configuration is working and see how it will be applied by <strong>Terraform</strong>.</p>
<p><code>$ terraform plan</code></p>
<p>Carefully read the output of this command as it indicates what <strong>Terraform</strong> is going to do once we pull the trigger. Errors in configuration should also appear here if we have made any.</p>
<p>Once happy with what the plan says, let&rsquo;s actually deploy the boxes we specified in the configuration files we made:</p>
<p><code>$ terraform apply</code></p>
<h2 id="checking-the-infrastructure">Checking the infrastructure</h2>
<p>If everything went right we should now have three virtual machines with static (not really static, but the <strong>DHCP</strong> server will give the same IP to the respective box every time) IP addresses and within the local DNS zone <strong>pygrn.lab</strong>. We can do a network mapping scan to make sure everything is as expected:</p>
<p><code>$ nmap -sn 192.168.122.0/24</code></p>
<p>To test the DNS zone we can use <strong>dig</strong> (contained in the <strong>bind9-dnsutils</strong> package in Debian) pointing at the networking interface our virtual machines use as <strong>DHCP</strong> and <strong>DNS</strong> server. This gateway is a virtual network card created by KVM which has a <strong>dnsmasq</strong> server instance attached to it. We&rsquo;ll use <code>+noall +answer</code> to filter the output so that it only shows us the section we&rsquo;re interested in. Here&rsquo;re the commands and their expected output:</p>
<p>Forward DNS:</p>
<p><strong><code>$ dig +noall +answer doris.pygrn.lab @192.168.122.1</code></strong><br>
<code>doris.pygrn.lab. 0 IN A 192.168.122.2</code></p>
<p>Reverse DNS:</p>
<p><strong><code>$ dig +noall +answer -x 192.168.122.2 @192.168.122.1</code></strong><br>
<code>2.122.168.192.in-addr.arpa. 0 IN PTR doris.pygrn.lab.</code></p>
<p>If the output of those commands matches the sample I&rsquo;ve just given we then have a fully working DNS zone with forward and reverse lookups working for our three virtual machines.</p>
<p>Let&rsquo;s now login into one the virtual machines through <strong>ssh</strong>:</p>
<p><code>$ ssh -i [/path/to/ssh/key] root@192.168.122.2</code></p>
<p>The <code>[path/to/ssh/key]</code> after the <strong>-i</strong> switch refers to the path in the computer serving as the hypervisor where the private key which corresponds to the public key we set up in the <strong>cloud_inits</strong> is stored. You should now have a bash prompt in the machine called <strong>doris</strong>.<br>
From here we can check our <strong>DNS</strong> settings as well if we wanted to; I&rsquo;ll drop a screengrab with a couple commands I ran to do it.</p>
<p><img src="/blog/img/sysadmin-playground2.png" alt=""></p>
<p>In the next chapter we&rsquo;ll do further configuration using <strong>Ansible</strong> and set up our first service with <strong>Docker</strong>.</p></article>
</main>
<footer>
<p>licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0">cc by-nc-sa 4.0</a></br>
standing up for freedom </p>
</footer>
</body>
</html>

